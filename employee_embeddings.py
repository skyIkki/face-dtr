import os
import json
import numpy as np
import logging
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- CORRECTED PATHS & NAMES ---
MOBILE_ARTIFACTS_DIR = "mobile_artifacts"

# 1. Correct the H5 model filename to match auto_retrain.py output
MODEL_H5_NAME = "face_embedding_model.h5"
MODEL_H5_PATH = os.path.join(MOBILE_ARTIFACTS_DIR, MODEL_H5_NAME)

# 2. Correct the TFLite model name (Optional, but good practice)
MODEL_TFLITE_PATH = os.path.join(MOBILE_ARTIFACTS_DIR, MODEL_H5_NAME.replace(".h5", ".tflite"))

# 3. Class mapping and output path names are already correct
CLASS_MAPPING_PATH = os.path.join(MOBILE_ARTIFACTS_DIR, "class_mapping.json")
EMBEDDINGS_OUTPUT_PATH = os.path.join(MOBILE_ARTIFACTS_DIR, "employee_embeddings.json")

# 4. CRITICAL: Correct the directory where auto_retrain.py extracted the frames
TRAINING_DATA_DIR = "user_training_data" 

# -----------------------------
# Initialization & Setup
# -----------------------------
try:
    logging.info(f"Loading class mapping from {CLASS_MAPPING_PATH}...")
    with open(CLASS_MAPPING_PATH, "r") as f:
        # { "0": "2019-0001", "1": "2019-0002", ... }
        class_mapping = json.load(f)
except FileNotFoundError:
    logging.critical(f"Class mapping file not found at {CLASS_MAPPING_PATH}. Ensure auto_retrain.py ran first.")
    exit(1)

try:
    logging.info(f"Loading Keras model from {MODEL_H5_PATH}...")
    # Load the H5 model generated by auto_retrain.py to generate the embeddings
    model = load_model(MODEL_H5_PATH, compile=False)
except FileNotFoundError:
    logging.critical(f"Keras model not found at {MODEL_H5_PATH}. Cannot generate embeddings.")
    exit(1)
except Exception as e:
    logging.critical(f"Failed to load Keras model: {e}")
    exit(1)


def preprocess_img(img_path, target_size=(160, 160)):
    """Loads, resizes, converts to array, and normalizes the image."""
    img = image.load_img(img_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = img_array / 255.0
    return img_array

employee_embeddings = {}
total_employees = len(class_mapping)
employees_processed = 0

logging.info(f"Starting embedding generation for {total_employees} employees from {TRAINING_DATA_DIR}...")

# -----------------------------
# Generate Embeddings
# -----------------------------
for class_index, employee_id in class_mapping.items():
    employees_processed += 1
    class_folder = os.path.join(TRAINING_DATA_DIR, employee_id)
    
    if not os.path.exists(class_folder):
        logging.warning(f"[{employees_processed}/{total_employees}] ⚠️ Training folder missing for {employee_id}. Skipping.")
        continue

    embeddings_list = []
    
    # Iterate through all images (frames) for this employee
    for img_name in os.listdir(class_folder):
        img_path = os.path.join(class_folder, img_name)
        if not img_name.lower().endswith(('.jpg', '.jpeg', '.png')):
            continue
            
        try:
            img_array = preprocess_img(img_path)
            # Predict the 128D embedding vector
            embedding = model.predict(img_array, verbose=0)[0]
            embeddings_list.append(embedding)
        except Exception as e:
            logging.error(f"❌ Failed to process {img_path}: {e}")

    if embeddings_list:
        # Calculate the average embedding vector (the master face representation)
        avg_embedding = np.mean(np.array(embeddings_list), axis=0)
        employee_embeddings[employee_id] = avg_embedding.tolist()
        logging.info(f"[{employees_processed}/{total_employees}] Generated average embedding for {employee_id} from {len(embeddings_list)} images.")
    else:
        logging.warning(f"[{employees_processed}/{total_employees}] No valid images processed for {employee_id}. Skipping.")


# -----------------------------
# Save Artifact
# -----------------------------
os.makedirs(MOBILE_ARTIFACTS_DIR, exist_ok=True)
with open(EMBEDDINGS_OUTPUT_PATH, "w") as f:
    json.dump(employee_embeddings, f, indent=4)

logging.info(f"✅ Successfully saved {len(employee_embeddings)} employee embeddings to {EMBEDDINGS_OUTPUT_PATH}")
