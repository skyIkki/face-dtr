import os
import json
import numpy as np
import logging
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- CORRECTED PATHS & NAMES ---
MOBILE_ARTIFACTS_DIR = "mobile_artifacts"
MODEL_H5_NAME = "face_embedding_model.h5" # Corrected name from auto_retrain.py

# Paths
MODEL_PATH = os.path.join(MOBILE_ARTIFACTS_DIR, MODEL_H5_NAME) # Use H5 model for prediction
CLASS_MAPPING_PATH = os.path.join(MOBILE_ARTIFACTS_DIR, "class_mapping.json")
OUTPUT_PATH = os.path.join(MOBILE_ARTIFACTS_DIR, "employee_embeddings.json")
TRAINING_DATA_PATH = "user_training_data" # Corrected directory from auto_retrain.py

# -----------------------------
# Load Model and Mapping
# -----------------------------
try:
    logging.info(f"Loading class mapping from {CLASS_MAPPING_PATH}...")
    with open(CLASS_MAPPING_PATH, "r") as f:
        # Format is {"0": "employee_id", "1": "employee_id", ...}
        raw_mapping = json.load(f) 
        # Extract only the employee IDs for iteration
        employee_ids = list(raw_mapping.values())
except FileNotFoundError:
    logging.critical(f"Class mapping file not found at {CLASS_MAPPING_PATH}. Ensure auto_retrain.py ran first.")
    exit(1)

try:
    logging.info(f"Loading Keras model from {MODEL_PATH}...")
    # Load the H5 model generated by auto_retrain.py
    model = load_model(MODEL_PATH, compile=False)
except FileNotFoundError:
    logging.critical(f"Keras model not found at {MODEL_PATH}. Cannot generate embeddings.")
    exit(1)


def get_embedding(img_path):
    """Load image and return normalized embedding vector from model"""
    img = image.load_img(img_path, target_size=(160, 160))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)  # Batch dimension
    img_array = img_array / 255.0  # Normalize
    embedding = model.predict(img_array, verbose=0)
    return embedding[0]  # Return as 1D array

# -----------------------------
# Generate Embeddings
# -----------------------------
employee_embeddings = {}
total_employees = len(employee_ids)
employees_processed = 0

logging.info(f"Starting embedding generation for {total_employees} employees from {TRAINING_DATA_PATH}...")

for employee_id in employee_ids:
    employees_processed += 1
    emp_folder = os.path.join(TRAINING_DATA_PATH, employee_id)
    
    if not os.path.exists(emp_folder):
        logging.warning(f"[{employees_processed}/{total_employees}] ⚠️ Training folder missing for {employee_id}. Skipping.")
        continue

    embeddings_list = []
    
    for img_file in os.listdir(emp_folder):
        if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
            continue
            
        img_path = os.path.join(emp_folder, img_file)
        try:
            embedding = get_embedding(img_path)
            embeddings_list.append(embedding)
        except Exception as e:
            logging.error(f"❌ Failed to process {img_path}: {e}")

    # Average embedding per employee
    if embeddings_list:
        avg_embedding = np.mean(embeddings_list, axis=0).tolist()
        employee_embeddings[employee_id] = avg_embedding
        logging.info(f"[{employees_processed}/{total_employees}] Generated average embedding for {employee_id}.")
    else:
        logging.warning(f"[{employees_processed}/{total_employees}] No valid images processed for {employee_id}.")

# -----------------------------
# Save Artifact
# -----------------------------
os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)
with open(OUTPUT_PATH, "w") as f:
    json.dump(employee_embeddings, f, indent=4)

logging.info(f"✅ Generated employee_embeddings.json with {len(employee_embeddings)} entries at {OUTPUT_PATH}")
